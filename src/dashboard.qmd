---
title: "Dashboard"
format:
  html:
    code-fold: true
    code-tools: true
    toc: true
params:
  data_dir: "data/csv"
  update_data: FALSE
  use_sysenv_creds: TRUE
  google_data_url: "https://docs.google.com/spreadsheets/d/1UFZkbh9oU4JHpYsrkDQcNmDyqD4J-qB74dhyMzIkqKs/edit?usp=sharing"
  sheet_name: "paper_data"
  data_fn: "paper-sources.csv"
---

This is a dashboard for the data collection and cleaning process.

All code is "folded" by default.
Select "Show All Code" from the menu at the upper right to reveal the code chunks.

## Set-up

We load `ggplot2` to make the following plot commands easier to type.

```{r}
library(ggplot2)
```

## Download

The data are stored in a Google sheet that we download if `params$update_data == TRUE`.

```{r}
if (!dir.exists(params$data_dir)) {
  message("Creating missing ",  params$data_dir, ".")
  dir.create(params$data_dir)
}

if (params$update_data) {
  if (params$use_sysenv_creds) {
    google_creds <- Sys.getenv("GMAIL_SURVEY")
    if (google_creds != "") {
      options(gargle_oauth_email = google_creds)
      googledrive::drive_auth()
    } else {
      message("No Google account information stored in `.Renviron`.")
      message("Add authorized Google account name to `.Renviron` using `usethist::edit_r_environ()`.")
    }
  }

  papers_data <- googlesheets4::read_sheet(ss = params$google_data_url,
                            sheet = params$sheet_name)
  out_fn <- file.path(params$data_dir, params$data_fn)
  readr::write_csv(papers_data, out_fn)
  message("Data updated: ", out_fn)
} else {
  message("Using stored data.")
  papers_data <- readr::read_csv(file.path(params$data_dir, params$data_fn),
                                 show_col_types = FALSE)
}
```

::: {.callout-note}

We have a separate tracking sheet that needs to be integrated into this workflow.

:::

### Synched Paperpile file from GitHub

We have configured Paperpile to synch a .bib formatted file directly with this repo on GitHub.
The file can be found here: `src/data/paperpile.bib`.

```{r}
refs_w_pdf <- bib2df::bib2df("data/paperpile-tac-has-pdf.bib")
refs_no_pdf <- bib2df::bib2df("data/paperpile-tac-no-pdf.bib")

refs_w_pdf <- refs_w_pdf |>
  dplyr::mutate(pdf = TRUE)

refs_no_pdf <- refs_no_pdf |>
  dplyr::mutate(pdf = FALSE)

refs <- dplyr::full_join(refs_w_pdf, refs_no_pdf)
```

## Clean

The downloaded data are sufficiently clean as of 2024-03-28 for the following visualizations.

## Visualize

<!-- ### Papers by publication date (Google Scholar) -->

<!-- ```{r} -->
<!-- #| label: fig-papers-by-pub-year -->
<!-- #| fig-cap: "Papers by publication year" -->
<!-- papers_data |> -->
<!--   ggplot() + -->
<!--   aes(x = pub_year) + -->
<!--   geom_bar() + -->
<!--     theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) -->
<!-- ``` -->

### Papers by publication date

The following uses the new has-pdf/no-pdf export workflow from Paperpile directly to Github.

```{r}
#| label: fig-papers-by-pub-year-paperpile
#| fig-cap: "Papers by publication year"
refs |>
  ggplot() +
  aes(x = YEAR, fill = pdf) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

<!-- ### Papers entered by analyst -->

<!-- ```{r} -->
<!-- #| label: fig-papers-by-analyst -->
<!-- #| fig-cap: "Papers entered by analyst" -->
<!-- papers_data |> -->
<!--   ggplot() + -->
<!--   aes(x = entered_by) + -->
<!--   geom_bar() -->
<!-- ``` -->


<!-- ### Papers by open status -->

<!-- #### On PSU network -->

<!-- ```{r} -->
<!-- #| label: fig-openable-papers -->
<!-- #| fig-cap: "Papers with openable URLs" -->
<!-- papers_data |> -->
<!--   ggplot() + -->
<!--   aes(x = url_openable) + -->
<!--   geom_bar() -->
<!-- ``` -->

<!-- #### Access via PSU Libraries -->
