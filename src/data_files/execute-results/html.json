{
  "hash": "c8541c161171606fb1e2d9fcd1a23ac7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: data\nbibliography: \"include/bib/teller-acuity-cards.bib\"\nparams:\n  data_dir: \"data/csv\"\n  update_data: TRUE\n  use_sysenv_creds: TRUE\n  google_data_fn: \"Legacy Project Acuity Data: By Paper\"\n---\n\n\n## Overview\n\nThis page describes the process of data gathering, cleaning, and visualization.\n\n## Gathering\n\nWe use a Google Sheet to store the by-study data:\n\n<https://docs.google.com/spreadsheets/d/1UFZkbh9oU4JHpYsrkDQcNmDyqD4J-qB74dhyMzIkqKs/edit#gid=0>\n\n::: {.callout-note}\n\n**Note**: There is no identifiable data here at the moment, so Google Sheets are a viable option.\n\nLater on, we start contacting authors, we will need to restrict access to that information for privacy reasons.\n\n:::\n\n::: {.callout-important}\n\nWe need a process for managing who has edit access.\n\n:::\n\nThe [`googledrive`](https://cran.r-project.org/web/packages/googledrive/index.html) package provides a convenient way to access documents stored on Google.\n\n### Download from Google as CSV\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!dir.exists(params$data_dir)) {\n  message(\"Creating missing \",  params$data_dir, \".\")\n  dir.create(params$data_dir)\n}\n\nif (params$update_data) {\n  if (params$use_sysenv_creds) {\n    google_creds <- Sys.getenv(\"GMAIL_SURVEY\")\n    if (google_creds != \"\") {\n      options(gargle_oauth_email = google_creds)\n      googledrive::drive_auth()\n    } else {\n      message(\"No Google account information stored in `.Renviron`.\")\n      message(\"Add authorized Google account name to `.Renviron` using `usethist::edit_r_environ()`.\")\n    }\n  }\n\n  googledrive::drive_download(\n    params$google_data_fn,\n    path = file.path(params$data_dir, \"by-paper.csv\"),\n    type = \"csv\",\n    overwrite = TRUE\n  )\n  message(\"Data updated.\")\n} else {\n  message(\"Using stored data.\")\n}\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nFile downloaded:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• 'Legacy Project Acuity Data: By Paper'\n  <id: 1UFZkbh9oU4JHpYsrkDQcNmDyqD4J-qB74dhyMzIkqKs>\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSaved locally as:\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• 'data/csv/by-paper.csv'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nData updated.\n```\n\n\n:::\n:::\n\n\nThe data file has been saved as a comma-separated value (CSV) format data file in a special directory called `csv/`.\n\n\n### Open CSV\n\nNext we load the data file.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacuity_df <-\n  readr::read_csv(file.path(params$data_dir, \"by-paper.csv\"), show_col_types = FALSE)\n```\n:::\n\n\nWe'll show the column (variable names) since these will be part of our data dictionary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacuity_cols <- names(acuity_df)\nacuity_cols\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"analyst_name\"     \"analyst_initials\"\n```\n\n\n:::\n:::\n\n\n### Create data dictionary\n\nWe'll start by creating a data dictionary so that we can refer to it later in our cleaning and data analysis.\nWe do this by creating a data frame or 'tibble' because this is a convenient format for manipulating the information.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacuity_data_dict <- tibble::tibble(col_name = names(acuity_df))\n```\n:::\n\n\nNow, we write a short description of each variable in the data file.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nacuity_data_dict <- acuity_data_dict |>\n  dplyr::mutate(col_desc = c(\"Last name of 1st author\",\n                             \"Full APA format citation\",\n                             \"Paper publication year\",\n                             \"Source in paper\",\n                             \"Reported age range in mos\",\n                             \"Age in mos as conformed by ROG\",\n                             \"Participants tested monocularly or binocularly\",\n                             \"Number of participants in group\",\n                             \"Testing distance in cm\",\n                             \"Starting card in cyc/deg\",\n                             \"Mean (group) acuity in cyc/deg\",\n                             \"Estimated lower limit of acuity in cyc/deg\",\n                             \"Teller Acuity Card closest equivalent to this lower limit\",\n                             \"Estimated upper limit of acuity in cyc/deg\",\n                             \"Country where data were collected\",\n                             \"TAC-I or TAC-II\"))\n\nacuity_data_dict |>\n  knitr::kable(format = 'html') |>\n  kableExtra::kable_classic()\n```\n:::\n\n\n## Data visualization\n\n::: {.callout-important}\n\nRick Gilmore decided to take the mean of the age range reported in the [@Xiang2021-ry] data and create a new variable *strictly* for visualization purposes, `age_grp_rog`.\n\n:::\n\nWe are still in the early phases of the project (as of 2024-03-19 08:36:53.912568), but it is good to start sketching the the data visualizations we will eventually want to see.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nacuity_df |>\n  ggplot() +\n  aes(x = age_grp_rog, y = mean_acuity_cyc_deg, color = country) +\n  geom_point() +\n  geom_smooth() +\n  facet_grid(cols = vars(binoc_monoc))\n```\n:::\n\n\n## By-individual data\n\nThe Gilmore lab has some archival data that we can potentially use in this project.\nThe following represents Rick Gilmore's work to gather, clean, and visualize these data.\n\n### Gathering\n\nThe de-identified archival data are stored in a Google sheet accessed by the lab Google account.\n\nFirst, we must authenticate to Google to access the relevant file and download it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(gargle_oauth_email = \"psubrainlab@gmail.com\")\ngoogledrive::drive_auth()\n```\n:::\n\n\nThen we download the relevant file.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngoogledrive::drive_download(\n  \"vep-session-log\",\n  path = file.path(params$data_dir, \"by-participant.csv\"),\n  type = \"csv\",\n  overwrite = TRUE\n)\n```\n:::\n\n\nUnlike the Google sheet newly created for the by-study data, this one requires a lot of cleaning.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngilmore_archival_df <-\n  readr::read_csv(file.path(params$data_dir, \"by-participant.csv\"),\n                  show_col_types = FALSE)\nnames(gilmore_archival_df)\n```\n:::\n\n\nWe'll keep `Date`, `Time`, `Sex`, `DOB`, `Teller Acuity Cards`, `Age at test`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngilmore_archival_df <- gilmore_archival_df |>\n  dplyr::select(Date, Time, Sex, DOB, `Teller Acuity Cards`, `Age at test`)\n```\n:::\n\n\nThen, let's filter those where we have TAC data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(gilmore_archival_df, unique(`Teller Acuity Cards`))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngilmore_archival_df <- gilmore_archival_df |>\n  dplyr::filter(!is.na(`Teller Acuity Cards`),\n                `Teller Acuity Cards` != \"not interested\")\n\ndim(gilmore_archival_df)\n```\n:::\n\n\n::: {.callout-note}\n\nThis file illustrates how making data FAIR from the outset can save work.\n\nThis one is not too terribly hard to parse, but it could have been better planned.\n\n:::\n\nWe'll extract the viewing distance with a regular expression.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngilmore_archival_df <- gilmore_archival_df |>\n  dplyr::mutate(view_dist_cm = stringr::str_extract(`Teller Acuity Cards`, \"[0-9]{2}cm\")) |>\n  dplyr::mutate(view_dist_cm = stringr::str_remove(view_dist_cm, \"cm\")) # remove 'cm'\ngilmore_archival_df$view_dist_cm\n```\n:::\n\n\nSimilarly, we'll extract the acuity in cyc/deg using a regular expression.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngilmore_archival_df <- gilmore_archival_df |>\n  # add 'cyc' to separate cyc/deg from Snellen acuity\n  dplyr::mutate(acuity_cyc_deg = stringr::str_extract(`Teller Acuity Cards`, \"[0-9]{1}[\\\\./]{1}[0-9]+ cyc\")) |>\n  dplyr::mutate(acuity_cyc_deg = stringr::str_remove(acuity_cyc_deg, \" cyc\")) |>\n  dplyr::mutate(acuity_cyc_deg = stringr::str_replace(acuity_cyc_deg, \"/\", \".\"))\n\ngilmore_archival_df$acuity_cyc_deg\n```\n:::\n\n\nNow, let's look at the age at test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngilmore_archival_df$`Age at test`\n```\n:::\n\nInstead, let's see what it looks like to compute age at test from the dates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngilmore_archival_df <- gilmore_archival_df |>\n  dplyr::mutate(age_at_test_days = lubridate::mdy(Date) - lubridate::mdy(DOB))\n\ngilmore_archival_df$age_at_test_days\n```\n:::\n\n\nThat seems reasonable for now.\n\nLet's see if we can plot these data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngilmore_archival_df |>\n  dplyr::mutate(acuity_cyc_deg = as.numeric(acuity_cyc_deg)) |>\n  ggplot() +\n  aes(x = age_at_test_days, y = acuity_cyc_deg, color = Sex) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  #theme_classic() +\n  theme(legend.position = \"bottom\", legend.title = element_blank()) \n```\n:::\n\n\n::: {.callout-note}\n\nBefore I stop, I'm going to add the by-participant data file to a `.gitignore` file, just to be extra careful.\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}